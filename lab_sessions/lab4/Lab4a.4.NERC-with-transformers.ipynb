{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab4a Named-entity-recognition using fine-tuned transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright: Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before reading this notebook make sure you have consulted **Lab3.4 SentimentClassification using transformer models**, which contains some disclaimers, tips and explains the sentence representations obtained from the transformer models.\n",
    "\n",
    "In this notebook we will use the simpletransformer package that provides a simple API on top of the transformer packge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Requires installing transformers, pytorch and simpletransformers\n",
    "#!conda install pytorch cpuonly -c pytorch\n",
    "#!pip install transformers\n",
    "#!pip install simpletransformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load a transformer model 'bert-base-NER' from the Hugging face repository, which is fine-tuned for Named Entity recognition: \n",
    "\n",
    "https://huggingface.co/models\n",
    "\n",
    "We need to load the model for the sequence classifcation and the tokenizer to convert the sentences into tokens according to the vocabulary of the model.\n",
    "\n",
    "Loading the model takes some time and requires you have sufficient memory to load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from simpletransformers.ner import NERModel\n",
    "#sentences = [\"Example sentence 1\", \"Example sentence 2\"]\n",
    "englishmodel = NERModel(\n",
    "        model_type=\"bert\",\n",
    "        model_name=\"dslim/bert-base-NER\",\n",
    "        use_cuda=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an instance of the NERModel that can be used for training, evaluation, and prediction in Named-Entity-Recognition (NER) tasks. The full parameter list for a NERModel object:\n",
    "\n",
    "* model_type: The type of model (bert, roberta)\n",
    "* model_name: Default Transformer model name or path to a directory containing Transformer model file (pytorch_nodel.bin).\n",
    "* labels (optional): A list of all Named Entity labels. If not given, [“O”, “B-MISC”, “I-MISC”, “B-PER”, “I-PER”, “B-ORG”, “I-ORG”, “B-LOC”, “I-LOC”] will be used.\n",
    "* args (optional): Default args will be used if this parameter is not provided. If provided, it should be a dict containing the args that should be changed in the default args.\n",
    "* use_cuda (optional): Use GPU if available. Setting to False will force model to use CPU only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f118804e8864427092e6654c89249745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f43789952a404b3cb6e045adcdba2a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Prediction:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions, raw_outputs = englishmodel.predict([\"Apple sued Samsung for patents last year.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'Apple': 'B-ORG'},\n",
       "  {'sued': 'O'},\n",
       "  {'Samsung': 'B-ORG'},\n",
       "  {'for': 'O'},\n",
       "  {'patents': 'O'},\n",
       "  {'last': 'O'},\n",
       "  {'year.': 'O'}]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dutchmodel = NERModel(\n",
    "        model_type=\"bert\",\n",
    "        model_name=\"Matthijsvanhof/bert-base-dutch-cased-finetuned-NER\",\n",
    "        use_cuda=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "887a0a51bf4e4f2bbc90e969630e4fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f516f24f1f4e9ea487051c5a19c7df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Prediction:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions, raw_outputs = dutchmodel.predict([\"Apple sleept Samsung voor de rechter vanwege schending van patenten.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'Apple': 'O'},\n",
       "  {'sleept': 'O'},\n",
       "  {'Samsung': 'B-MISC'},\n",
       "  {'voor': 'O'},\n",
       "  {'de': 'O'},\n",
       "  {'rechter': 'O'},\n",
       "  {'vanwege': 'O'},\n",
       "  {'schending': 'O'},\n",
       "  {'van': 'O'},\n",
       "  {'patenten.': 'O'}]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option for Dutch NER (https://huggingface.co/flair/ner-dutch-large):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-21 13:32:26,936 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-PER, S-LOC, B-MISC, E-MISC, B-ORG, E-ORG, I-ORG, I-PER, B-LOC, I-LOC, E-LOC, I-MISC, <START>, <STOP>\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "# load tagger\n",
    "tagger = SequenceTagger.load(\"flair/ner-dutch-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence[11]: \"Apple sleept Samsung voor de rechter vanwege schending van patenten.\" → [\"Apple\"/ORG, \"Samsung\"/ORG]\n",
      "The following NER tags are found:\n",
      "Span[0:1]: \"Apple\" → ORG (1.0000)\n",
      "Span[2:3]: \"Samsung\" → ORG (1.0000)\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence(\"Apple sleept Samsung voor de rechter vanwege schending van patenten.\")\n",
    "\n",
    "# predict NER tags\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# print sentence\n",
    "print(sentence)\n",
    "\n",
    "# print predicted NER spans\n",
    "print('The following NER tags are found:')\n",
    "# iterate over entities and print\n",
    "for entity in sentence.get_spans('ner'):\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of this notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
