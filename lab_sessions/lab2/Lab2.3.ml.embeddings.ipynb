{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab2.3 Machine learning using embeddings\n",
    "\n",
    "Copyright: Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL\n",
    "\n",
    "In this notebook, you are going to use word embeddings instead of the one-hot-encoding of words. Word embeddings have many advantages:\n",
    "\n",
    "* they capture similarities across words that can be learned from massive amounts of text data without annotation\n",
    "* machine learning can easily exploit similarity because the embeddings are also represented as vectors\n",
    "* the word embedding vectors are much smaller (100 up to 500 dimensions) and more dense than one-hot-encodings, which results in more efficient and compact models that also generalize better.\n",
    "\n",
    "At the end of this notebook, you should have learned:\n",
    "\n",
    "* how to replace the words in your training set by their embeddings\n",
    "* how to train a classifier enriched with embeddings\n",
    "* how to represent the words for any unseen text as embeddings\n",
    "* how to add embeddings to our NERC system\n",
    "* how to work with some popular data sets for NERC with which such embeddings can be combined\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Quick introduction to embeddings\n",
    "\n",
    "Extracting features manually can get us a long way. In addition to lemma and part-of-speech, people have used other information: features of the previous words (on the left) or the next words (on the right), whether the current word starts with a capital, whether it is an abbreviation, etc.\n",
    "\n",
    "A recent alternative way to create a 'semantic' representation of a word is by word embeddings: mapping words (or phrases) from the vocabulary to vectors of real numbers. Conceptually it involves a mathematical embedding from a space with many dimensions per word to a continuous vector space with a much lower dimension. For this reason, they are called dense representations.\n",
    "\n",
    "In linguistics, word embeddings were discussed in the research area of distributional semantics. The idea is to quantify and categorize semantic similarities between linguistic items based on their distributional properties in large samples of language data. The underlying notion is that \"a word is characterized by the company it keeps\" (Firth). Embeddings are however the weights in the hidden layer of a neural network that is trained to predict the contexts rather than representing the context in a vector directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will load pre-trained word embeddings called word2vec, created by Google. The embeddings have 300 dimensions.\n",
    "\n",
    "First, please download the file from [their google drive](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit). Then, create a folder in the same directory as this notebook and unpack the word2vec file in that folder.\n",
    "\n",
    "We will load the embedding model with the Gensim package that we used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load the file using the gensim library (this takes a while):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The Google model should be in the same directory. If not adapt the path accordingly.\n",
    "path = r\"C:\\path\\to\\GoogleNews-vectors-negative300.bin\"\n",
    "\n",
    "word_embedding_model = gensim.models.KeyedVectors.load_word2vec_format(path, binary=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have limited memory to load the model, you add a limit to only load part of the vocabulary. In the next call only the first 500K words are loaded:\n",
    "\n",
    "```word_embedding_model = gensim.models.KeyedVectors.load_word2vec_format('/Users/piek/Desktop/ONDERWIJS/data/models/GoogleNews-vectors-negative300.bin', binary=True, limit=500000)  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embeddings capture certain meaning aspects of words. Previous research has shown that they can partially capture simiarity (\"tapas\" is similar to \"pintxos\"), relatedness (tapas relates to Spain), and analogy (\"Paris\" is to \"France\" as \"Rome\" is to \"Italy\"). \n",
    "\n",
    "To get an idea of these properties of embeddings, we can compute the cosine similarity between two word vectors. We will expect for example, that \"cat\" and \"tiger\" are more similar than \"cat\" and \"Germany\". Feel free to play a bit with word1 and word2 below to get some feeling of the information these embeddings capture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5683571]]\n"
     ]
    }
   ],
   "source": [
    "word1='Apple'\n",
    "word2='Google'\n",
    "word1_vector=np.array(word_embedding_model[word1]).reshape(1, -1)\n",
    "word2_vector=np.array(word_embedding_model[word2]).reshape(1, -1)\n",
    "#print(word1_vector)\n",
    "print(cosine_similarity(word1_vector, word2_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the most similar words to some word, say 'slave_labor':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('slave_laborers', 0.6745792627334595), ('sweatshops', 0.6110795140266418), ('indentured_servitude', 0.5665937066078186), ('slaves', 0.5655405521392822), ('sweatshop', 0.555057942867279), ('indentured_labor', 0.5519518256187439), ('slavery', 0.5504497289657593), ('sex_slaves', 0.5418298244476318), ('indentured_servants', 0.528259813785553), ('enslavement', 0.5266590118408203), ('sweatshop_labor', 0.5248557925224304), ('concentration_camps', 0.5246363878250122), ('concentration_camp', 0.5233564972877502), ('laogai', 0.517486035823822), ('enslaved', 0.5159811973571777), ('gulag', 0.5139166116714478), ('slave', 0.5118827819824219), ('Gulags', 0.5074896216392517), ('Soviet_Gulag', 0.5051531791687012), ('cocoa_plantations', 0.5045973062515259)]\n"
     ]
    }
   ],
   "source": [
    "print(word_embedding_model.most_similar('slave_labor', topn=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Using embeddings in a NERC model\n",
    "\n",
    "Next, we will use the same example of Named Entity Recognition and Classification (NERC) as in the previous notebook but now replace the one-hot-vector for the vocabularies by their dense embeddings.\n",
    "\n",
    "We use the same text as before and process it using SpaCy to get the words and the part of speech. We define the labels in the same way as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "text=\"Germany's representative to the European Union\"\n",
    "\n",
    "doc=nlp(text)\n",
    "\n",
    "## The series of labels that go with the word tokens from the input text\n",
    "y=['B-LOC', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now replace the one-hot input representation of our words with embeddings. We generate our input data by simply looking up each word in the embeddings model. If we find it, we add the embedding vector to the training input, if not we add a vector with 300 zero values.\n",
    "\n",
    "The following code creates an array from all the tokens in the spaCy document object \"doc\" by taking the embedding vectors for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This word is not in the word2vec vocabulary: 's\n",
      "This word is not in the word2vec vocabulary: to\n"
     ]
    }
   ],
   "source": [
    "training_input=[]\n",
    "for token in doc:\n",
    "    word=token.text  #the next word from the tokenized text\n",
    "    # we check if our word \n",
    "    # is inside the model vocabulary (loaded with the Google word2vec embeddings)\n",
    "    if word in word_embedding_model:\n",
    "        # in this case the word was found and vector is assigned with its embedding vector as the value\n",
    "        vector=word_embedding_model[word]\n",
    "    else: \n",
    "        # if the word does not exist in the embeddings vocabulary, \n",
    "        # we create a vector with all zeros.\n",
    "        # The Google word2vec model has 300 dimensions so we creat a vector with 300 zeros\n",
    "        vector=[0]*300\n",
    "        print('This word is not in the word2vec vocabulary:', word)\n",
    "    training_input.append(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that for two tokens from the spaCy output, we did not get an embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the first element in our training_input, which is the same size as the tokenized sentence but the words are replaced by embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the training input =  7\n",
      "[ 0.25976562  0.140625    0.24707031  0.00958252 -0.25       -0.08251953\n",
      " -0.09912109 -0.35351562 -0.1484375   0.1484375  -0.03540039 -0.05249023\n",
      "  0.09277344 -0.14257812 -0.01483154  0.01647949  0.03710938  0.18847656\n",
      " -0.03955078 -0.05786133  0.26757812  0.10693359 -0.04345703  0.06738281\n",
      " -0.00177765  0.1328125  -0.16308594 -0.05908203 -0.22558594  0.12207031\n",
      "  0.10791016 -0.19433594 -0.16210938 -0.14257812  0.09033203 -0.14648438\n",
      " -0.12109375  0.09960938  0.26367188  0.12695312  0.140625    0.11083984\n",
      "  0.02697754 -0.01635742  0.00292969  0.14746094 -0.06542969 -0.16699219\n",
      "  0.03662109  0.14941406 -0.14746094  0.06835938 -0.09228516  0.12207031\n",
      " -0.09179688  0.09082031 -0.38476562  0.03051758 -0.21679688 -0.12597656\n",
      " -0.08642578 -0.26171875 -0.08496094 -0.13964844 -0.02832031 -0.203125\n",
      "  0.29101562 -0.13574219 -0.07226562  0.16308594 -0.19042969  0.22265625\n",
      "  0.05566406  0.21289062  0.05053711 -0.09814453  0.12158203  0.01000977\n",
      "  0.15234375 -0.02233887  0.07324219 -0.27148438 -0.01977539 -0.07128906\n",
      "  0.13964844 -0.06542969  0.08886719  0.01452637  0.03344727  0.12158203\n",
      " -0.0703125  -0.02282715 -0.15332031  0.22265625 -0.22265625 -0.18164062\n",
      "  0.08642578 -0.26367188 -0.03735352  0.04321289  0.03039551 -0.19042969\n",
      "  0.07080078  0.37695312 -0.01318359 -0.02526855 -0.00775146  0.02868652\n",
      " -0.00350952 -0.08203125  0.15234375 -0.20996094  0.16796875  0.05322266\n",
      "  0.13476562  0.05102539  0.00454712  0.02099609  0.37890625  0.24707031\n",
      " -0.25585938 -0.27148438  0.0402832  -0.00604248 -0.11865234 -0.05957031\n",
      "  0.14550781 -0.265625   -0.47851562  0.02709961  0.03833008  0.02441406\n",
      " -0.1640625  -0.19921875 -0.08984375 -0.16015625 -0.06079102 -0.03491211\n",
      "  0.2109375   0.03637695  0.20898438 -0.00588989  0.015625    0.10986328\n",
      "  0.08154297  0.11328125  0.296875    0.30664062 -0.12890625 -0.14550781\n",
      "  0.11474609  0.02258301 -0.02905273 -0.08544922 -0.06201172 -0.08740234\n",
      " -0.21777344  0.10986328  0.14550781  0.21679688  0.07177734  0.02294922\n",
      "  0.13964844 -0.15917969  0.22265625 -0.03515625 -0.03515625  0.07763672\n",
      " -0.12695312  0.25       -0.24707031  0.04345703  0.05786133 -0.1171875\n",
      " -0.11425781 -0.29492188  0.11523438 -0.16992188 -0.05078125 -0.09228516\n",
      "  0.04101562 -0.3984375  -0.24707031 -0.19238281  0.4375      0.12988281\n",
      "  0.12890625  0.03271484 -0.22558594  0.20800781  0.03564453 -0.06982422\n",
      "  0.12792969 -0.00300598  0.17285156  0.15722656  0.12890625 -0.16210938\n",
      " -0.24121094 -0.3984375   0.02246094 -0.06176758  0.12792969  0.02526855\n",
      "  0.01867676 -0.01745605 -0.15722656 -0.06201172 -0.22460938 -0.02087402\n",
      "  0.00192261 -0.17382812  0.09521484  0.23046875 -0.16992188 -0.22363281\n",
      "  0.23632812  0.05126953  0.13867188 -0.00238037 -0.05664062 -0.2890625\n",
      " -0.11767578 -0.11767578 -0.28710938 -0.0324707   0.04150391 -0.08447266\n",
      "  0.1953125  -0.24121094 -0.19433594 -0.04418945  0.0559082   0.01293945\n",
      "  0.05444336  0.12988281 -0.02502441  0.19726562 -0.17675781 -0.15234375\n",
      "  0.21484375  0.00515747  0.01269531  0.11132812 -0.02722168  0.15625\n",
      " -0.20800781 -0.02416992 -0.11621094 -0.08789062 -0.02075195  0.01782227\n",
      "  0.00439453  0.18261719 -0.19433594  0.26367188  0.04467773  0.01293945\n",
      "  0.15917969  0.0859375   0.12988281  0.00141907  0.02441406  0.25976562\n",
      "  0.28320312  0.11669922 -0.03564453 -0.25       -0.0559082   0.29296875\n",
      "  0.04833984 -0.03393555  0.13769531 -0.19140625  0.21875    -0.08300781\n",
      " -0.10058594  0.20117188 -0.11425781 -0.00595093 -0.06982422 -0.046875\n",
      " -0.06591797  0.02453613 -0.27148438  0.19628906  0.22265625  0.02429199\n",
      "  0.04394531  0.10253906 -0.06079102  0.11816406 -0.06445312  0.11376953\n",
      " -0.17285156  0.171875   -0.19433594  0.00817871  0.06835938 -0.14160156]\n"
     ]
    }
   ],
   "source": [
    "print(\"The length of the training input = \",len(training_input))\n",
    "#### the first token has the following embedding values\n",
    "print(training_input[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as in the earlier cases, once we have the vector representations, we can use them to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearSVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.svm.LinearSVC.html\">?<span>Documentation for LinearSVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearSVC()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "lin_clf = svm.LinearSVC()\n",
    "lin_clf.fit(training_input, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing the model** Let's say we want to test our model with the sentence: 'I love beer from Munich'. What we need to do is to preprocess the text in the same way as the training data by using spaCy (otherwise, we may get a mismatch in features), and next replace each word by an embedding vector as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence='I love beer from Berlin'\n",
    "test_doc=nlp(test_sentence)\n",
    "\n",
    "test_input=[]\n",
    "\n",
    "for token in test_doc:\n",
    "    word=token.text\n",
    "    if word in word_embedding_model:\n",
    "        vector=word_embedding_model[word]\n",
    "    else:\n",
    "        vector=[0]*300\n",
    "    test_input.append(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our representation is the same, we can ask the classifier to make a prediction for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'O' 'O' 'O' 'B-LOC']\n"
     ]
    }
   ],
   "source": [
    "pred=lin_clf.predict(test_input)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier assigned IOB tags to the tokens in order and the final obtained the label 'B-LOC', which is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have now trained and testing your first embeddings-based NERC model. Note that the word 'Munich' is not in the training data but the system still managed to make a correct(!) prediction because the embedding matched.\n",
    "\n",
    "So far you have just worked with a few toy examples. In order to obtain a good performance machine learning systems may need thousands and sometimes hundreds of thousands training examples. The vocabulary of a language is large and there is also large variation in expressions. Having only a few examples for each words or expression requires to have massive amounts of text.\n",
    "\n",
    "To some extent, word embedding resolve the issue of *data sparseness*, as words unseen in the training data may still be similar to other words that are in the training data. Word embeddings are derived from millions of documents (billions of tokens) and are likely to have embeddings for most words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Combining embeddings with one-hot encoding\n",
    "\n",
    "So how can we combine the word embeddings with one-hot-encodings for other features?\n",
    "\n",
    "We are first going to get the one-hot encodings of the text as we did in the previous notebook using the DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vec = DictVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_instances=[]\n",
    "for token in doc:\n",
    "    one_training_instance={'part-of-speech': token.pos_, 'lemma': token.lemma_} # this concatenates the PoS and Lemma\n",
    "    training_instances.append(one_training_instance)\n",
    "the_array = vec.fit_transform(training_instances).toarray() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we inspect the array, we see it holds 7 rows, each row representing one token, and 12 columns, each column representing a feature value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 12)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_array.shape\n",
    "# ROWS are WORDS, COLUMNS are FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# the first token values\n",
    "print(the_array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"lemma='s\" 'lemma=European' 'lemma=Germany' 'lemma=Union'\n",
      " 'lemma=representative' 'lemma=the' 'lemma=to' 'part-of-speech=ADP'\n",
      " 'part-of-speech=DET' 'part-of-speech=NOUN' 'part-of-speech=PART'\n",
      " 'part-of-speech=PROPN']\n"
     ]
    }
   ],
   "source": [
    "print(vec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(the_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training_input array represented the same text with embeddings. Let's inspect the array for the embeddings using the numpy module (imported as np at the start of this notebook!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 300)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(training_input).shape\n",
    "# ROWS are WORDS, COLUMNS are EMBEDDINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has the same rows but 300 additional features. We can now *concatenate* the features for each word using numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_input=np.array(the_array)\n",
    "embeddings_input=np.array(training_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that the number of rows is the same across the two arrays and each row corresponds to the same token instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining the values for: 0  from the features and the embeddings\n",
      "Combining the values for: 1  from the features and the embeddings\n",
      "Combining the values for: 2  from the features and the embeddings\n",
      "Combining the values for: 3  from the features and the embeddings\n",
      "Combining the values for: 4  from the features and the embeddings\n",
      "Combining the values for: 5  from the features and the embeddings\n",
      "Combining the values for: 6  from the features and the embeddings\n"
     ]
    }
   ],
   "source": [
    "#### num_words is the number of rows\n",
    "num_words=features_input.shape[0]\n",
    "concat_input=[] # for storing the result of concatenating\n",
    "for index in range(num_words):\n",
    "    print('Combining the values for:', index, \" from the features and the embeddings\")\n",
    "    representation=list(features_input[index]) + list(embeddings_input[index]) # concatenate features per word\n",
    "    concat_input.append(representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we check the shape, we see it has the same rows but now the combination of features result in 312 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 312)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(concat_input).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets inspect the concatenated vector for the first token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.259765625, 0.140625, 0.2470703125, 0.00958251953125, -0.25, -0.08251953125, -0.09912109375, -0.353515625, -0.1484375, 0.1484375, -0.035400390625, -0.052490234375, 0.0927734375, -0.142578125, -0.01483154296875, 0.0164794921875, 0.037109375, 0.1884765625, -0.03955078125, -0.057861328125, 0.267578125, 0.10693359375, -0.04345703125, 0.0673828125, -0.00177764892578125, 0.1328125, -0.1630859375, -0.05908203125, -0.2255859375, 0.1220703125, 0.10791015625, -0.1943359375, -0.162109375, -0.142578125, 0.09033203125, -0.146484375, -0.12109375, 0.099609375, 0.263671875, 0.126953125, 0.140625, 0.11083984375, 0.0269775390625, -0.016357421875, 0.0029296875, 0.1474609375, -0.0654296875, -0.1669921875, 0.03662109375, 0.1494140625, -0.1474609375, 0.068359375, -0.09228515625, 0.1220703125, -0.091796875, 0.0908203125, -0.384765625, 0.030517578125, -0.216796875, -0.1259765625, -0.08642578125, -0.26171875, -0.0849609375, -0.1396484375, -0.0283203125, -0.203125, 0.291015625, -0.1357421875, -0.072265625, 0.1630859375, -0.1904296875, 0.22265625, 0.0556640625, 0.212890625, 0.050537109375, -0.09814453125, 0.12158203125, 0.010009765625, 0.15234375, -0.0223388671875, 0.0732421875, -0.271484375, -0.019775390625, -0.0712890625, 0.1396484375, -0.0654296875, 0.0888671875, 0.0145263671875, 0.033447265625, 0.12158203125, -0.0703125, -0.0228271484375, -0.1533203125, 0.22265625, -0.22265625, -0.181640625, 0.08642578125, -0.263671875, -0.037353515625, 0.043212890625, 0.0303955078125, -0.1904296875, 0.07080078125, 0.376953125, -0.01318359375, -0.0252685546875, -0.00775146484375, 0.0286865234375, -0.003509521484375, -0.08203125, 0.15234375, -0.2099609375, 0.16796875, 0.05322265625, 0.134765625, 0.051025390625, 0.004547119140625, 0.02099609375, 0.37890625, 0.2470703125, -0.255859375, -0.271484375, 0.040283203125, -0.00604248046875, -0.11865234375, -0.0595703125, 0.1455078125, -0.265625, -0.478515625, 0.027099609375, 0.038330078125, 0.0244140625, -0.1640625, -0.19921875, -0.08984375, -0.16015625, -0.060791015625, -0.034912109375, 0.2109375, 0.036376953125, 0.208984375, -0.005889892578125, 0.015625, 0.10986328125, 0.08154296875, 0.11328125, 0.296875, 0.306640625, -0.12890625, -0.1455078125, 0.11474609375, 0.0225830078125, -0.029052734375, -0.08544921875, -0.06201171875, -0.08740234375, -0.2177734375, 0.10986328125, 0.1455078125, 0.216796875, 0.07177734375, 0.02294921875, 0.1396484375, -0.1591796875, 0.22265625, -0.03515625, -0.03515625, 0.07763671875, -0.126953125, 0.25, -0.2470703125, 0.04345703125, 0.057861328125, -0.1171875, -0.1142578125, -0.294921875, 0.115234375, -0.169921875, -0.05078125, -0.09228515625, 0.041015625, -0.3984375, -0.2470703125, -0.1923828125, 0.4375, 0.1298828125, 0.12890625, 0.03271484375, -0.2255859375, 0.2080078125, 0.03564453125, -0.06982421875, 0.1279296875, -0.0030059814453125, 0.1728515625, 0.1572265625, 0.12890625, -0.162109375, -0.2412109375, -0.3984375, 0.0224609375, -0.061767578125, 0.1279296875, 0.0252685546875, 0.0186767578125, -0.0174560546875, -0.1572265625, -0.06201171875, -0.224609375, -0.0208740234375, 0.001922607421875, -0.173828125, 0.09521484375, 0.23046875, -0.169921875, -0.2236328125, 0.236328125, 0.05126953125, 0.138671875, -0.00238037109375, -0.056640625, -0.2890625, -0.11767578125, -0.11767578125, -0.287109375, -0.032470703125, 0.04150390625, -0.08447265625, 0.1953125, -0.2412109375, -0.1943359375, -0.044189453125, 0.055908203125, 0.012939453125, 0.054443359375, 0.1298828125, -0.0250244140625, 0.197265625, -0.1767578125, -0.15234375, 0.21484375, 0.005157470703125, 0.0126953125, 0.111328125, -0.0272216796875, 0.15625, -0.2080078125, -0.024169921875, -0.1162109375, -0.087890625, -0.020751953125, 0.017822265625, 0.00439453125, 0.1826171875, -0.1943359375, 0.263671875, 0.044677734375, 0.012939453125, 0.1591796875, 0.0859375, 0.1298828125, 0.0014190673828125, 0.0244140625, 0.259765625, 0.283203125, 0.11669921875, -0.03564453125, -0.25, -0.055908203125, 0.29296875, 0.04833984375, -0.033935546875, 0.1376953125, -0.19140625, 0.21875, -0.0830078125, -0.1005859375, 0.201171875, -0.1142578125, -0.005950927734375, -0.06982421875, -0.046875, -0.06591796875, 0.0245361328125, -0.271484375, 0.1962890625, 0.22265625, 0.0242919921875, 0.0439453125, 0.1025390625, -0.060791015625, 0.1181640625, -0.064453125, 0.11376953125, -0.1728515625, 0.171875, -0.1943359375, 0.0081787109375, 0.068359375, -0.1416015625]\n"
     ]
    }
   ],
   "source": [
    "print(concat_input[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Representing the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we need to represent the test data in the same way as the train data. So also when testing we need to create an array with the same 312 features. We first use SpaCy again to get the linguistics features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'part-of-speech': 'PRON', 'lemma': 'I'}, {'part-of-speech': 'VERB', 'lemma': 'love'}, {'part-of-speech': 'NOUN', 'lemma': 'beer'}, {'part-of-speech': 'ADP', 'lemma': 'from'}, {'part-of-speech': 'PROPN', 'lemma': 'Munich'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5, 10)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence='I love beer from Munich'\n",
    "test_doc=nlp(test_sentence)\n",
    "\n",
    "test_instances=[]\n",
    "for token in test_doc:\n",
    "    one_test_instance={'part-of-speech': token.pos_, 'lemma': token.lemma_} # this concatenates the PoS and Lemma\n",
    "    test_instances.append(one_test_instance)\n",
    "\n",
    "print(test_instances)\n",
    "the_test_array = vec.fit_transform(test_instances).toarray()\n",
    "\n",
    "the_test_array.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(the_test_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a problem. The training and test array do not have the same number of columns. For the training set we had 12 features, and now we have 10. The vectorizer takes the properties and values from the data. Since the training and test data are different also the vector representation are different. Not only in size but also mixing positions and values differently.\n",
    "\n",
    "The problem is that we used the *fit_transform* function that we used for training and that we modified the model of *vec* according to the test data. We thus ruined out model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lemma=I' 'lemma=Munich' 'lemma=beer' 'lemma=from' 'lemma=love'\n",
      " 'part-of-speech=ADP' 'part-of-speech=NOUN' 'part-of-speech=PRON'\n",
      " 'part-of-speech=PROPN' 'part-of-speech=VERB']\n"
     ]
    }
   ],
   "source": [
    "print(vec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should have used the *transform* function instead of *fit_transform* but this is now too late."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 10)\n",
      "[[1. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "the_test_array = vec.transform(test_instances).toarray()\n",
    "\n",
    "print(the_test_array.shape)\n",
    "print(the_test_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lemma=I' 'lemma=Munich' 'lemma=beer' 'lemma=from' 'lemma=love'\n",
      " 'part-of-speech=ADP' 'part-of-speech=NOUN' 'part-of-speech=PRON'\n",
      " 'part-of-speech=PROPN' 'part-of-speech=VERB']\n"
     ]
    }
   ],
   "source": [
    "print(vec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we rebuild the model *vec* from the training data, we can fix this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"lemma='s\" 'lemma=European' 'lemma=Germany' 'lemma=Union'\n",
      " 'lemma=representative' 'lemma=the' 'lemma=to' 'part-of-speech=ADP'\n",
      " 'part-of-speech=DET' 'part-of-speech=NOUN' 'part-of-speech=PART'\n",
      " 'part-of-speech=PROPN']\n"
     ]
    }
   ],
   "source": [
    "vec = DictVectorizer()\n",
    "the_array = vec.fit_transform(training_instances).toarray() \n",
    "print(vec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can transform the test data without fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 12)\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "the_test_array = vec.transform(test_instances).toarray()\n",
    "\n",
    "print(the_test_array.shape)\n",
    "print(the_test_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to fix this is by applying the vectorizer function to both the train and test data to build a model for all data and next represent the data for both sets separately by transforming it to the vector dimensions of the overarching model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Harmonizing one-hot-vectors across training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first combines the training and test instances into a single data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'part-of-speech': 'PROPN', 'lemma': 'Germany'}, {'part-of-speech': 'PART', 'lemma': \"'s\"}, {'part-of-speech': 'NOUN', 'lemma': 'representative'}, {'part-of-speech': 'ADP', 'lemma': 'to'}, {'part-of-speech': 'DET', 'lemma': 'the'}, {'part-of-speech': 'PROPN', 'lemma': 'European'}, {'part-of-speech': 'PROPN', 'lemma': 'Union'}, {'part-of-speech': 'PRON', 'lemma': 'I'}, {'part-of-speech': 'VERB', 'lemma': 'love'}, {'part-of-speech': 'NOUN', 'lemma': 'beer'}, {'part-of-speech': 'ADP', 'lemma': 'from'}, {'part-of-speech': 'PROPN', 'lemma': 'Munich'}]\n"
     ]
    }
   ],
   "source": [
    "vec = DictVectorizer()\n",
    "## First we concatenate the training and test instances and fit these to a vector representation\n",
    "train_and_test_instance = training_instances + test_instances\n",
    "print(train_and_test_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We adapt the model by calling *fit_transform* over the combination of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 19)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_array = vec.fit_transform(train_and_test_instance).toarray()\n",
    "the_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we now have 12 rows (tokens) and 19 values. From this shared feature space, we need to recover the data corresponding to the training data and the data corresponding to the test data. Since the order is based on the concatenation, we can take the length of the training_instances to separate the first part as the training data and the second part as the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(the_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"lemma='s\" 'lemma=European' 'lemma=Germany' 'lemma=I' 'lemma=Munich'\n",
      " 'lemma=Union' 'lemma=beer' 'lemma=from' 'lemma=love'\n",
      " 'lemma=representative' 'lemma=the' 'lemma=to' 'part-of-speech=ADP'\n",
      " 'part-of-speech=DET' 'part-of-speech=NOUN' 'part-of-speech=PART'\n",
      " 'part-of-speech=PRON' 'part-of-speech=PROPN' 'part-of-speech=VERB']\n"
     ]
    }
   ],
   "source": [
    "print(vec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training words = (7, 19)\n",
      "Number of test words = (5, 19)\n"
     ]
    }
   ],
   "source": [
    "# For the training set we take the first part of the data upto the length of the training_instances\n",
    "training_onehot = the_array[:len(training_instances)]\n",
    "#For the test set, we take the remaining part of the data starting at the length of the training_instances\n",
    "#(remember that '0' is the first data element)\n",
    "test_onehot = the_array[len(training_instances):]\n",
    "\n",
    "print('Number of training words =', training_onehot.shape)\n",
    "print('Number of test words =', test_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(training_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(test_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we ensured that the feature space is the same for the training and test data. Next we get the embeddings for both sets and combine these with the one-got-vector representations. We start with the training data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_training_input=np.array(training_onehot)\n",
    "embeddings_training_input=np.array(training_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7, 319)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words=training_onehot.shape[0]\n",
    "concat_train_input=[]\n",
    "for index in range(num_words):\n",
    "    print(index)\n",
    "    representation=list(training_onehot[index]) + list(embeddings_training_input[index]) # concatenate features per word\n",
    "    concat_train_input.append(representation)\n",
    "\n",
    "# we check the shape\n",
    "np.array(concat_train_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.259765625, 0.140625, 0.2470703125, 0.00958251953125, -0.25, -0.08251953125, -0.09912109375, -0.353515625, -0.1484375, 0.1484375, -0.035400390625, -0.052490234375, 0.0927734375, -0.142578125, -0.01483154296875, 0.0164794921875, 0.037109375, 0.1884765625, -0.03955078125, -0.057861328125, 0.267578125, 0.10693359375, -0.04345703125, 0.0673828125, -0.00177764892578125, 0.1328125, -0.1630859375, -0.05908203125, -0.2255859375, 0.1220703125, 0.10791015625, -0.1943359375, -0.162109375, -0.142578125, 0.09033203125, -0.146484375, -0.12109375, 0.099609375, 0.263671875, 0.126953125, 0.140625, 0.11083984375, 0.0269775390625, -0.016357421875, 0.0029296875, 0.1474609375, -0.0654296875, -0.1669921875, 0.03662109375, 0.1494140625, -0.1474609375, 0.068359375, -0.09228515625, 0.1220703125, -0.091796875, 0.0908203125, -0.384765625, 0.030517578125, -0.216796875, -0.1259765625, -0.08642578125, -0.26171875, -0.0849609375, -0.1396484375, -0.0283203125, -0.203125, 0.291015625, -0.1357421875, -0.072265625, 0.1630859375, -0.1904296875, 0.22265625, 0.0556640625, 0.212890625, 0.050537109375, -0.09814453125, 0.12158203125, 0.010009765625, 0.15234375, -0.0223388671875, 0.0732421875, -0.271484375, -0.019775390625, -0.0712890625, 0.1396484375, -0.0654296875, 0.0888671875, 0.0145263671875, 0.033447265625, 0.12158203125, -0.0703125, -0.0228271484375, -0.1533203125, 0.22265625, -0.22265625, -0.181640625, 0.08642578125, -0.263671875, -0.037353515625, 0.043212890625, 0.0303955078125, -0.1904296875, 0.07080078125, 0.376953125, -0.01318359375, -0.0252685546875, -0.00775146484375, 0.0286865234375, -0.003509521484375, -0.08203125, 0.15234375, -0.2099609375, 0.16796875, 0.05322265625, 0.134765625, 0.051025390625, 0.004547119140625, 0.02099609375, 0.37890625, 0.2470703125, -0.255859375, -0.271484375, 0.040283203125, -0.00604248046875, -0.11865234375, -0.0595703125, 0.1455078125, -0.265625, -0.478515625, 0.027099609375, 0.038330078125, 0.0244140625, -0.1640625, -0.19921875, -0.08984375, -0.16015625, -0.060791015625, -0.034912109375, 0.2109375, 0.036376953125, 0.208984375, -0.005889892578125, 0.015625, 0.10986328125, 0.08154296875, 0.11328125, 0.296875, 0.306640625, -0.12890625, -0.1455078125, 0.11474609375, 0.0225830078125, -0.029052734375, -0.08544921875, -0.06201171875, -0.08740234375, -0.2177734375, 0.10986328125, 0.1455078125, 0.216796875, 0.07177734375, 0.02294921875, 0.1396484375, -0.1591796875, 0.22265625, -0.03515625, -0.03515625, 0.07763671875, -0.126953125, 0.25, -0.2470703125, 0.04345703125, 0.057861328125, -0.1171875, -0.1142578125, -0.294921875, 0.115234375, -0.169921875, -0.05078125, -0.09228515625, 0.041015625, -0.3984375, -0.2470703125, -0.1923828125, 0.4375, 0.1298828125, 0.12890625, 0.03271484375, -0.2255859375, 0.2080078125, 0.03564453125, -0.06982421875, 0.1279296875, -0.0030059814453125, 0.1728515625, 0.1572265625, 0.12890625, -0.162109375, -0.2412109375, -0.3984375, 0.0224609375, -0.061767578125, 0.1279296875, 0.0252685546875, 0.0186767578125, -0.0174560546875, -0.1572265625, -0.06201171875, -0.224609375, -0.0208740234375, 0.001922607421875, -0.173828125, 0.09521484375, 0.23046875, -0.169921875, -0.2236328125, 0.236328125, 0.05126953125, 0.138671875, -0.00238037109375, -0.056640625, -0.2890625, -0.11767578125, -0.11767578125, -0.287109375, -0.032470703125, 0.04150390625, -0.08447265625, 0.1953125, -0.2412109375, -0.1943359375, -0.044189453125, 0.055908203125, 0.012939453125, 0.054443359375, 0.1298828125, -0.0250244140625, 0.197265625, -0.1767578125, -0.15234375, 0.21484375, 0.005157470703125, 0.0126953125, 0.111328125, -0.0272216796875, 0.15625, -0.2080078125, -0.024169921875, -0.1162109375, -0.087890625, -0.020751953125, 0.017822265625, 0.00439453125, 0.1826171875, -0.1943359375, 0.263671875, 0.044677734375, 0.012939453125, 0.1591796875, 0.0859375, 0.1298828125, 0.0014190673828125, 0.0244140625, 0.259765625, 0.283203125, 0.11669921875, -0.03564453125, -0.25, -0.055908203125, 0.29296875, 0.04833984375, -0.033935546875, 0.1376953125, -0.19140625, 0.21875, -0.0830078125, -0.1005859375, 0.201171875, -0.1142578125, -0.005950927734375, -0.06982421875, -0.046875, -0.06591796875, 0.0245361328125, -0.271484375, 0.1962890625, 0.22265625, 0.0242919921875, 0.0439453125, 0.1025390625, -0.060791015625, 0.1181640625, -0.064453125, 0.11376953125, -0.1728515625, 0.171875, -0.1943359375, 0.0081787109375, 0.068359375, -0.1416015625]\n"
     ]
    }
   ],
   "source": [
    "print(concat_train_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test_input=np.array(test_onehot)\n",
    "embeddings_test_input=np.array(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5, 319)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words=test_onehot.shape[0]\n",
    "concat_test_input=[]\n",
    "for index in range(num_words):\n",
    "    print(index)\n",
    "    representation=list(test_onehot[index]) + list(embeddings_test_input[index]) # concatenate features per word\n",
    "    concat_test_input.append(representation)\n",
    "\n",
    "# we check the shape\n",
    "np.array(concat_test_input).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train the classifier in the same way as we did before but now with the concatenated features, where the one-hot-vectors are aligned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearSVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.svm.LinearSVC.html\">?<span>Documentation for LinearSVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearSVC()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_clf.fit(concat_train_input, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'O' 'O' 'O' 'B-LOC']\n"
     ]
    }
   ],
   "source": [
    "pred=lin_clf.predict(concat_test_input)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of this notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
